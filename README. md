# ğŸ—„ï¸ PLP Bookstore â€“ MongoDB Week 1 Assignment Submission

## ğŸš€ Objective
This weekâ€™s goal was to learn and demonstrate MongoDB fundamentals, including:
- Setting up MongoDB (locally or via MongoDB Atlas)
- Creating databases and collections
- Performing CRUD operations
- Writing advanced queries using projection, sorting, and pagination
- Building aggregation pipelines
- Implementing indexes to improve performance

---

## ğŸ“‚ Files Included in This Submission

| File Name | Description |
|------------|--------------|
| `insert_books.js` | A Node.js script that connects to MongoDB and inserts multiple book documents into the `plp_bookstore` database. |
| `queries.js` | A collection of MongoDB commands demonstrating CRUD operations, advanced queries, aggregation pipelines, and indexing. |
| `README.md` | This file â€” explains the work done, structure, and how to run the scripts. |
| `screenshot.jpg` | Screenshot showing the `books` collection in MongoDB Compass or Atlas. |

---

## ğŸ› ï¸ Setup Instructions

### ğŸ§© Step 1: Database Setup
- I created (or would create) a database named **`plp_bookstore`**.
- Inside it, I created a **`books`** collection.

### ğŸ§© Step 2: Data Insertion
- The `insert_books.js` script inserts at least **10 book documents**.
- Each book contains:
  - `title`  
  - `author`  
  - `genre`  
  - `published_year`  
  - `price`  
  - `in_stock`  
  - `pages`  
  - `publisher`

Example:  
```json
{
  "title": "The Hobbit",
  "author": "J.R.R. Tolkien",
  "genre": "Fantasy",
  "published_year": 1937,
  "price": 14.99,
  "in_stock": true,
  "pages": 310,
  "publisher": "George Allen & Unwin"
}
#How to run the scripts 
Open the terminal and navigate to your project folder.

*Run:
npm init -y
npm install mongodb
node insert_books.js
Once books are inserted, open mongosh or MongoDB Compass.


*Run the commands from queries.js to perform CRUD, sorting, and aggregation.
If using MongoDB Atlas:
Replace the connection string in insert_books.js with your Atlas URI.

#MongoDB Operations Performed

#Basic CRUD Operations
â—Create: Inserted multiple documents using insertMany().
â—Read: Used find() to query books by genre, author, and year.
â—Update: Used updateOne() to modify book prices.
â—Delete: Used deleteOne() to remove a book by title.

#Advanced Queries
â—Filtered books that are in stock and published after 2010.
â—Used projection to display only title, author, and price.
â—Implemented sorting by price (ascending and descending)
â—Implemented pagination using limit() and skip() (5 books per page).

#Aggregation Pipelines
Used MongoDBâ€™s aggregation framework to analyze and group data.
1.Average Price by Genre
db.books.aggregate([
  { $group: { _id: "$genre", averagePrice: { $avg: "$price" } } },
  { $sort: { averagePrice: -1 } }
]);

2.Author with most books
db.books.aggregate([
  { $group: { _id: "$author", totalBooks: { $sum: 1 } } },
  { $sort: { totalBooks: -1 } },
  { $limit: 1 }
]);

#Indexing
To improve query performance:
Created a single-field index on the title field.
Created a compound index on author and published_year.
Used the explain("executionStats") method to verify performance improvements.
Example:
// Create index on title
db.books.createIndex({ title: 1 });

// Create compound index on author and published_year
db.books.createIndex({ author: 1, published_year: -1 });

// Check performance with explain()
db.books.find({ title: "The Hobbit" }).explain("executionStats");

#Expected Outcome
Database: plp_bookstore
Collection: books
Successfully inserted at least 10 book documents
All CRUD, filtering, and sorting queries executed correctly
Aggregation pipelines produced accurate analytical results
Indexes demonstrated faster query performance using explain()

#Screenshot
â—A screenshot (screenshot.jpg) is included in the repository showing:
The plp_bookstore database
â—The books collection
â—Sample book data inserted successfully

ğŸ Summary
This project demonstrates my understanding of MongoDB fundamentals, including:
â—Database and collection creation
â—CRUD operations
â—Advanced querying techniques
â—Aggregation pipelines for data analysis
â—Indexing for query optimization
